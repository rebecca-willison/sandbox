{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "welsh-hamilton",
   "metadata": {},
   "source": [
    "## CNN PyTorch Example\n",
    "Some adaptation from https://www.kaggle.com/juiyangchang/cnn-with-pytorch-0-995-accuracy.\n",
    "\n",
    "### Import modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "matched-trader",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.autograd import Variable\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "studied-privilege",
   "metadata": {},
   "source": [
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stuffed-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/rebeccawillison/Documents/research/stat-9340/hw5/mnist0_train_b.txt'\n",
    "mnist0 = np.array(pd.read_fwf(data_path, header = None)).transpose()\n",
    "data_path = '/Users/rebeccawillison/Documents/research/stat-9340/hw5/mnist9_train_b.txt'\n",
    "mnist9 = np.array(pd.read_fwf(data_path, header = None)).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "other-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset training dataset & standardize\n",
    "train_X = np.c_[mnist0[:,0:1000], mnist9[:,0:1000]].transpose()\n",
    "train_Y = np.append(np.full(1000, 0), np.full(1000, 1))\n",
    "train = pd.DataFrame(np.insert(train_X, 1, train_Y, axis=1)).rename(columns={0:'label'})\n",
    "\n",
    "# create test dataset & standardize\n",
    "test_X = np.c_[mnist0[:,2500:3000], mnist9[:,2500:3000]].transpose()\n",
    "test_Y = np.append(np.full(500, 0), np.full(500, 1))\n",
    "test = pd.DataFrame(test_X)\n",
    "\n",
    "train_file = '/Users/rebeccawillison/Documents/research/stat-9340/hw5/mnist_train.csv'\n",
    "train.to_csv(train_file, index = False)\n",
    "test_file = '/Users/rebeccawillison/Documents/research/stat-9340/hw5/mnist_test.csv'\n",
    "test.to_csv(test_file, index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-pursuit",
   "metadata": {},
   "source": [
    "### Data loading functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "level-willow",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST_data(Dataset):\n",
    "    def __init__(self, file_path, \n",
    "                 transform = transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), \n",
    "                     transforms.Normalize(mean=(0.5,), std=(0.5,))])\n",
    "                ):\n",
    "\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        if len(df.columns) == n_pixels:\n",
    "            # test data\n",
    "            self.X = df.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = None\n",
    "        else:\n",
    "            # training data\n",
    "            self.X = df.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n",
    "            self.y = torch.from_numpy(df.iloc[:,0].values.astype(int))\n",
    "\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if self.y is not None:\n",
    "            return self.transform(self.X[idx]), self.y[idx]\n",
    "        else:\n",
    "            return self.transform(self.X[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "quick-bunch",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "n_pixels = 28*28\n",
    "\n",
    "train_dataset = MNIST_data(train_file, transform = transforms.Compose(\n",
    "                            [transforms.ToTensor(), \n",
    "                             transforms.Normalize(mean=(0.5,), std=(0.5,))]))\n",
    "test_dataset = MNIST_data(test_file)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size = 1000,\n",
    "                                          shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-gathering",
   "metadata": {},
   "source": [
    "### Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "toxic-chamber",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(myCNN, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(32, 32, kernel_size=3, stride=1, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 7 * 7, 30),\n",
    "            nn.Sigmoid(),\n",
    "            nn.Linear(30, 2),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "        \n",
    "        for m in self.features.children():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
    "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "        \n",
    "        for m in self.classifier.children():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "            elif isinstance(m, nn.BatchNorm1d):\n",
    "                m.weight.data.fill_(1)\n",
    "                m.bias.data.zero_()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "model = myCNN()\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-1)\n",
    "exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-compromise",
   "metadata": {},
   "source": [
    "### Functions for training and model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "martial-authority",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    exp_lr_scheduler.step()\n",
    "\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = Variable(data), Variable(target)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "def evaluate(data_loader):\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    for data, target in data_loader:\n",
    "        data, target = Variable(data, volatile=True), Variable(target)\n",
    "        output = model(data)\n",
    "        loss += F.cross_entropy(output, target, size_average=False).data[0]\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
    "        \n",
    "    loss /= len(data_loader.dataset)\n",
    "    \n",
    "def prediction(data_loader):\n",
    "    model.eval()\n",
    "    test_pred = torch.LongTensor()\n",
    "    \n",
    "    for i, data in enumerate(data_loader):\n",
    "        data = Variable(data)\n",
    "        output = model(data)\n",
    "        \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-layer",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "upper-motorcycle",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "for epoch in range(n_epochs):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "invalid-asian",
   "metadata": {},
   "source": [
    "### Get test predictions and check accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "metallic-master",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = prediction(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "contrary-iceland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.715\n"
     ]
    }
   ],
   "source": [
    "test_pred = preds[:,1].detach().numpy()\n",
    "test_pred[test_pred > np.mean(test_pred)] = 1\n",
    "test_pred[test_pred != 1] = 0\n",
    "print('Accuracy:', sum(test_pred == test_Y)/1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unavailable-ordinance",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
